{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import face_recognition as fr\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = Path('../dataset')\n",
    "face_dir = Path('../faces')\n",
    "os.makedirs(face_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images: 77736.\n"
     ]
    }
   ],
   "source": [
    "total_images = 0\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    total_images += len(files)\n",
    "\n",
    "print(f'Total Images: {total_images}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Image: 100/77736\n",
      "Processing Image: 200/77736\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 31\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m###################### RESIZE IMAGE #################################\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#####################################################################\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m##     aspect_ratio = img.width / img.height                       ##\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#####################################################################\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#####################################################################\u001b[39;00m\n\u001b[0;32m     30\u001b[0m image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(image)   \n\u001b[1;32m---> 31\u001b[0m face_box \u001b[38;5;241m=\u001b[39m \u001b[43mfr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(face_box)):\n\u001b[0;32m     34\u001b[0m     top, right, bottom, left \u001b[38;5;241m=\u001b[39m face_box[i]\n",
      "File \u001b[1;32mc:\\Users\\lefte\\miniforge3\\lib\\site-packages\\face_recognition\\api.py:121\u001b[0m, in \u001b[0;36mface_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face\u001b[38;5;241m.\u001b[39mrect), img\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m _raw_face_locations(img, number_of_times_to_upsample, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face), img\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_raw_face_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[1;32mc:\\Users\\lefte\\miniforge3\\lib\\site-packages\\face_recognition\\api.py:105\u001b[0m, in \u001b[0;36m_raw_face_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cnn_face_detector(img, number_of_times_to_upsample)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mface_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "count = 1\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "# for root, dirs, files in tqdm(os.walk(image_dir)):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.webp'):\n",
    "\n",
    "            if count%100 == 0:\n",
    "                print(f\"Processing Image: {count}/{total_images}\")\n",
    "            count += 1\n",
    "\n",
    "            image_path = os.path.join(root, filename)\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "            ###################### RESIZE IMAGE #################################\n",
    "            #####################################################################\n",
    "            ##     aspect_ratio = img.width / img.height                       ##\n",
    "            ##     max_size = (512, 512)                                       ##\n",
    "            ##         if img.size[0] > img.size[1]:                           ##\n",
    "            ##             new_width = max_size[0]                             ##\n",
    "            ##             new_height = round(max_size[0] / aspect_ratio)      ##\n",
    "            ##         else:                                                   ##\n",
    "            ##             new_height = max_size[1]                            ##\n",
    "            ##             new_width = round(max_size[1] * aspect_ratio)       ##\n",
    "            ##         img = img.resize((new_width, new_height))               ##\n",
    "            #####################################################################\n",
    "            #####################################################################\n",
    "            \n",
    "            image = np.array(image)   \n",
    "            face_box = fr.face_locations(image)\n",
    "\n",
    "            for i in range(len(face_box)):\n",
    "                top, right, bottom, left = face_box[i]\n",
    "                image_array = np.array(image)\n",
    "                face_image = image_array[top+1:bottom, left+1:right]\n",
    "                pil_image = Image.fromarray(face_image)\n",
    "                \n",
    "                base_filename, _ = os.path.splitext(filename)\n",
    "                class_name = os.path.basename(root)\n",
    "                class_dir = os.path.join(face_dir, class_name)\n",
    "                os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "                target_path = os.path.join(class_dir, f\"img-{base_filename}-face-{i+1}.jpg\")\n",
    "                pil_image.save(target_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
