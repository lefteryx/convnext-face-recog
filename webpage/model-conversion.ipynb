{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.onnx\n",
    "import onnx\n",
    "from onnx import helper\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "import timm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeXtArcFace(nn.Module):\n",
    "    def __init__(self, model_name, embedding_size, pretrained=True):\n",
    "        super(ConvNeXtArcFace, self).__init__()\n",
    "        self.convnext = timm.create_model(model_name, pretrained=pretrained)\n",
    "        self.convnext.reset_classifier(num_classes=0, global_pool='avg')\n",
    "      \n",
    "    def forward(self, x):\n",
    "        x = self.convnext.forward_features(x) # \n",
    "        x = F.avg_pool2d(x, 7).flatten(1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNeXtArcFace(\n",
       "  (convnext): MobileNetV3(\n",
       "    (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNormAct2d(\n",
       "      32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (blocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): ConvBnAct(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (aa): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvBnAct(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (aa): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvBnAct(\n",
       "          (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (aa): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvBnAct(\n",
       "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (aa): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): UniversalInvertedResidual(\n",
       "          (dw_start): ConvNormAct(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "          (pw_exp): ConvNormAct(\n",
       "            (conv): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (dw_mid): ConvNormAct(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (pw_proj): ConvNormAct(\n",
       "            (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "          (dw_end): Identity()\n",
       "          (layer_scale): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): UniversalInvertedResidual(\n",
       "          (dw_start): Identity()\n",
       "          (pw_exp): ConvNormAct(\n",
       "            (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (dw_mid): ConvNormAct(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (pw_proj): ConvNormAct(\n",
       "            (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "          (dw_end): Identity()\n",
       "          (layer_scale): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): UniversalInvertedResidual(\n",
       "          (dw_start): Identity()\n",
       "          (pw_exp): ConvNormAct(\n",
       "            (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (dw_mid): ConvNormAct(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (pw_proj): ConvNormAct(\n",
       "            (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "          (dw_end): Identity()\n",
       "          (layer_scale): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): UniversalInvertedResidual(\n",
       "          (dw_start): Identity()\n",
       "          (pw_exp): ConvNormAct(\n",
       "            (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (dw_mid): ConvNormAct(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (pw_proj): ConvNormAct(\n",
       "            (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "          (dw_end): Identity()\n",
       "          (layer_scale): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): UniversalInvertedResidual(\n",
       "          (dw_start): Identity()\n",
       "          (pw_exp): ConvNormAct(\n",
       "            (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (dw_mid): ConvNormAct(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (pw_proj): ConvNormAct(\n",
       "            (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "          (dw_end): Identity()\n",
       "          (layer_scale): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): UniversalInvertedResidual(\n",
       "          (dw_start): ConvNormAct(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "          (pw_exp): ConvNormAct(\n",
       "            (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (dw_mid): Identity()\n",
       "          (se): Identity()\n",
       "          (pw_proj): ConvNormAct(\n",
       "            (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "          (dw_end): Identity()\n",
       "          (layer_scale): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): UniversalInvertedResidual(\n",
       "          (dw_start): ConvNormAct(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "          (pw_exp): ConvNormAct(\n",
       "            (conv): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (dw_mid): ConvNormAct(\n",
       "            (conv): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (pw_proj): ConvNormAct(\n",
       "            (conv): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "          (dw_end): Identity()\n",
       "          (layer_scale): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): UniversalInvertedResidual(\n",
       "          (dw_start): ConvNormAct(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "          (pw_exp): ConvNormAct(\n",
       "            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (dw_mid): ConvNormAct(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512, bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (pw_proj): ConvNormAct(\n",
       "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "          (dw_end): Identity()\n",
       "          (layer_scale): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): UniversalInvertedResidual(\n",
       "          (dw_start): Identity()\n",
       "          (pw_exp): ConvNormAct(\n",
       "            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (dw_mid): ConvNormAct(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512, bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (pw_proj): ConvNormAct(\n",
       "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "          (dw_end): Identity()\n",
       "          (layer_scale): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): UniversalInvertedResidual(\n",
       "          (dw_start): Identity()\n",
       "          (pw_exp): ConvNormAct(\n",
       "            (conv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (dw_mid): ConvNormAct(\n",
       "            (conv): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (pw_proj): ConvNormAct(\n",
       "            (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "          (dw_end): Identity()\n",
       "          (layer_scale): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): UniversalInvertedResidual(\n",
       "          (dw_start): Identity()\n",
       "          (pw_exp): ConvNormAct(\n",
       "            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (dw_mid): ConvNormAct(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (pw_proj): ConvNormAct(\n",
       "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "          (dw_end): Identity()\n",
       "          (layer_scale): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): UniversalInvertedResidual(\n",
       "          (dw_start): Identity()\n",
       "          (pw_exp): ConvNormAct(\n",
       "            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (dw_mid): ConvNormAct(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (pw_proj): ConvNormAct(\n",
       "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNormAct2d(\n",
       "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "          (dw_end): Identity()\n",
       "          (layer_scale): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): ConvBnAct(\n",
       "          (conv): Conv2d(128, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (aa): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "    (conv_head): Conv2d(960, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (norm_head): BatchNormAct2d(\n",
       "      1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (act2): Identity()\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (classifier): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ckpt = torch.load(\"../checkpoints/model.pth\")\n",
    "# model_state_dict = ckpt['model_state_dict']\n",
    "model = ConvNeXtArcFace(model_name=\"mobilenetv4_conv_small\", embedding_size=960)\n",
    "# model.load_state_dict(model_state_dict)\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "dummy_output = model(dummy_input)\n",
    "onnx_model_path = \"model.onnx\"\n",
    "torch.onnx.export(model, dummy_input, onnx_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(onnx_model_path)\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "ort_session = onnxruntime.InferenceSession(onnx_model_path, providers=[\"CUDAExecutionProvider\"])\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(dummy_input)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "np.testing.assert_allclose(to_numpy(dummy_output), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "print(\"Exported model looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(onnx_model_path)\n",
    "\n",
    "name_map = {\"input.1\": \"input_1\"}\n",
    "\n",
    "new_inputs = []\n",
    "for inp in onnx_model.graph.input:\n",
    "    if inp.name in name_map:\n",
    "        new_inp = helper.make_tensor_value_info(name_map[inp.name],\n",
    "                                                inp.type.tensor_type.elem_type,\n",
    "                                                [dim.dim_value for dim in inp.type.tensor_type.shape.dim])\n",
    "        new_inputs.append(new_inp)\n",
    "    else:\n",
    "        new_inputs.append(inp)\n",
    "\n",
    "onnx_model.graph.ClearField(\"input\")\n",
    "onnx_model.graph.input.extend(new_inputs)\n",
    "\n",
    "for node in onnx_model.graph.node:\n",
    "    for i, input_name in enumerate(node.input):\n",
    "        if input_name in name_map:\n",
    "            node.input[i] = name_map[input_name]\n",
    "\n",
    "onnx.save(onnx_model, 'model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Function `__call__` contains input name(s) x, y with unsupported characters which will be renamed to transpose_132_x, add_44_y in the SavedModel.\n",
      "INFO:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.pb\\assets\n",
      "INFO:absl:Writing fingerprint to model.pb\\fingerprint.pb\n"
     ]
    }
   ],
   "source": [
    "tf_rep = prepare(onnx_model)\n",
    "tf_model_path = \"model.pb\"\n",
    "tf_rep.export_graph(tf_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 02:33:10.507924: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-02 02:33:10.716988: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-02 02:33:10.816641: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-02 02:33:10.817251: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-02 02:33:10.966320: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-02 02:33:12.033420: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:root:TensorFlow Decision Forests 1.9.1 is compatible with the following TensorFlow Versions: ['2.16.1']. However, TensorFlow 2.16.2 was detected. This can cause issues with the TF API and symbols in the custom C++ ops. See the TF and TF-DF compatibility table at https://github.com/tensorflow/decision-forests/blob/main/documentation/known_issues.md#compatibility-table.\n",
      "2024-07-02 02:33:15.038409: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 02:33:15.195648: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 02:33:15.195723: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 02:33:15.199274: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 02:33:15.199355: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 02:33:15.199387: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 02:33:15.426756: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 02:33:15.426885: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 02:33:15.426934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-07-02 02:33:15.426992: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 02:33:15.429366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1753 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-07-02 02:33:15.671170: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 02:33:15.671231: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-07-02 02:33:15.671423: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-02 02:33:15.672577: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 02:33:15.672629: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 02:33:15.672658: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 02:33:15.672801: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 02:33:15.672820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-07-02 02:33:15.672841: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 02:33:15.672864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1753 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "!wsl tensorflowjs_converter --input_format=tf_saved_model model.pb  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'model_state_dict': model.state_dict()}, \"model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
