{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset_path, train_path, val_path, test_path, val_ratio, test_ratio):\n",
    "    for class_name in os.listdir(dataset_path):\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        train_class_path = os.path.join(train_path, class_name)\n",
    "        val_class_path = os.path.join(val_path, class_name)\n",
    "        test_class_path = os.path.join(test_path, class_name)\n",
    "\n",
    "        if not os.path.exists(train_class_path):\n",
    "            os.makedirs(train_class_path)\n",
    "        if not os.path.exists(val_class_path):\n",
    "            os.makedirs(val_class_path)\n",
    "        if not os.path.exists(test_class_path):\n",
    "            os.makedirs(test_class_path)\n",
    "\n",
    "        images = os.listdir(class_path)\n",
    "        random.shuffle(images)\n",
    "\n",
    "        val_count = int(len(images) * val_ratio)\n",
    "        test_count = int(len(images) * test_ratio)\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            image = images[i]\n",
    "            image_path = os.path.join(class_path, image)\n",
    "            if i < val_count:\n",
    "                shutil.copy(image_path, val_class_path)\n",
    "            elif i < val_count + test_count:\n",
    "                shutil.copy(image_path, test_class_path)\n",
    "            else:\n",
    "                shutil.copy(image_path, train_class_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split into training, validation and testing datasets\n",
      "Training dataset:\t split/train\n",
      "Validation dataset:\t split/val\n",
      "Testing dataset:\t split/test\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'part-1-1'\n",
    "train_path = 'split/train'\n",
    "val_path = 'split/val'\n",
    "test_path = 'split/test'\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.2\n",
    "\n",
    "split_dataset(dataset_path, train_path, val_path, test_path, val_ratio, test_ratio)\n",
    "\n",
    "print('Dataset split into training, validation and testing datasets.\\n')\n",
    "print('Training dataset:\\t', train_path)\n",
    "print('Validation dataset:\\t', val_path)\n",
    "print('Testing dataset:\\t', test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of images in training dataset:\t 6514\n",
      "Number of images in validation dataset:\t 923\n",
      "Number of images in testing dataset:\t 1852\n"
     ]
    }
   ],
   "source": [
    "train_count = sum([len(files) for r, d, files in os.walk(train_path)])\n",
    "val_count = sum([len(files) for r, d, files in os.walk(val_path)])\n",
    "test_count = sum([len(files) for r, d, files in os.walk(test_path)])\n",
    "\n",
    "print('\\nNumber of images in training dataset:\\t', train_count)\n",
    "print('Number of images in validation dataset:\\t', val_count)\n",
    "print('Number of images in testing dataset:\\t', test_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
